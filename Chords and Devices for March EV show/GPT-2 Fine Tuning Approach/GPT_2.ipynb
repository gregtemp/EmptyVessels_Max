{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GPT_2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/ak9250/gpt-2-colab/blob/master/GPT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"Pzxl1vYX-1kk","colab_type":"text"},"source":["Setup:\n","\n","1) Make sure GPU is enabled, go to edit->notebook settings->Hardware Accelerator GPU\n","\n","2) Make a copy to your google drive, click on copy to drive in panel"]},{"cell_type":"markdown","metadata":{"id":"iW0abT07ZkhZ","colab_type":"text"},"source":["Note: Colab will reset after 12 hours make sure to save your model checkpoints to google drive around 10-11 hours mark or before, then go to runtime->reset all runtimes. Now copy your train model back into colab and start training again from the previous checkpoint."]},{"cell_type":"markdown","metadata":{"id":"iLXW02eIYpcB","colab_type":"text"},"source":["clone and cd into repo, nshepperd's fork https://github.com/nshepperd/gpt-2"]},{"cell_type":"code","metadata":{"id":"ICYu3w9hIJkC","colab_type":"code","outputId":"baa36997-4023-41d8-f484-e9c0809c33e0","executionInfo":{"status":"ok","timestamp":1582914143832,"user_tz":300,"elapsed":3198,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!git clone https://github.com/gregtemp/gpt-2.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'gpt-2'...\n","remote: Enumerating objects: 6, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 372 (delta 2), reused 0 (delta 0), pack-reused 366\u001b[K\n","Receiving objects: 100% (372/372), 4.42 MiB | 8.47 MiB/s, done.\n","Resolving deltas: 100% (201/201), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6eEIs3ApZUVO","colab_type":"code","outputId":"d9cc7f52-eccd-4c8c-c6cb-8c4b12ed62c4","executionInfo":{"status":"ok","timestamp":1582914146968,"user_tz":300,"elapsed":409,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd gpt-2"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gpt-2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qtn1qZPgZLb0","colab_type":"text"},"source":["Install requirements"]},{"cell_type":"code","metadata":{"id":"434oOx0bZH6J","colab_type":"code","outputId":"0b366ed4-7a47-4932-b7e5-728b14ec18f0","executionInfo":{"status":"ok","timestamp":1582914163878,"user_tz":300,"elapsed":15085,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":701}},"source":["!pip3 install -r requirements.txt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting fire>=0.1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n","\u001b[K     |████████████████████████████████| 81kB 9.9MB/s \n","\u001b[?25hCollecting regex==2017.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n","\u001b[K     |████████████████████████████████| 604kB 29.1MB/s \n","\u001b[?25hRequirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n","Collecting tqdm==4.31.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n","\u001b[K     |████████████████████████████████| 51kB 10.0MB/s \n","\u001b[?25hCollecting toposort==1.5\n","  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n","Building wheels for collected packages: fire, regex\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103528 sha256=f2ed5220e271fbeda83f85ba1d1488b1c31d2bf51b40694116d0e0e581d1dd84\n","  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n","  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for regex: filename=regex-2017.4.5-cp36-cp36m-linux_x86_64.whl size=533180 sha256=5fa451071e1469cfb76a60932386338a127eecfb823c80a89bf8abbad32c791c\n","  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n","Successfully built fire regex\n","Installing collected packages: fire, regex, tqdm, toposort\n","  Found existing installation: regex 2019.12.20\n","    Uninstalling regex-2019.12.20:\n","      Successfully uninstalled regex-2019.12.20\n","  Found existing installation: tqdm 4.28.1\n","    Uninstalling tqdm-4.28.1:\n","      Successfully uninstalled tqdm-4.28.1\n","Successfully installed fire-0.2.1 regex-2017.4.5 toposort-1.5 tqdm-4.31.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tqdm"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"WvUQhgK3PQ4L","colab_type":"text"},"source":["Mount drive to access google drive for saving and accessing checkpoints later. Have to log in to your google account"]},{"cell_type":"code","metadata":{"id":"FNpf6R4ahYSN","colab_type":"code","outputId":"9ae766da-48dd-429e-b93c-c5fcc90c52fb","executionInfo":{"status":"ok","timestamp":1582914199476,"user_tz":300,"elapsed":21021,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o1hrgeKFYsuE","colab_type":"text"},"source":["Download the model data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A498TySgHYyF","outputId":"60ab9176-45f6-42cd-d6e2-4a73dc8ce883","executionInfo":{"status":"ok","timestamp":1582914206688,"user_tz":300,"elapsed":3332,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":646}},"source":["!python3 download_model.py 117M"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Fetching checkpoint: 1.00kit [00:00, 961kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 63.8Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 933kit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001:  23%|████▏             | 116M/498M [00:01<00:04, 79.0Mit/s]\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/urllib3/response.py\", line 362, in _error_catcher\n","    yield\n","  File \"/usr/local/lib/python3.6/dist-packages/urllib3/response.py\", line 444, in read\n","    data = self._fp.read(amt)\n","  File \"/usr/lib/python3.6/http/client.py\", line 458, in read\n","    b = bytearray(amt)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"download_model.py\", line 26, in <module>\n","    for chunk in r.iter_content(chunk_size=chunk_size):\n","  File \"/usr/local/lib/python3.6/dist-packages/requests/models.py\", line 750, in generate\n","    for chunk in self.raw.stream(chunk_size, decode_content=True):\n","  File \"/usr/local/lib/python3.6/dist-packages/urllib3/response.py\", line 496, in stream\n","    data = self.read(amt=amt, decode_content=decode_content)\n","  File \"/usr/local/lib/python3.6/dist-packages/urllib3/response.py\", line 461, in read\n","    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n","  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n","    self.gen.throw(type, value, traceback)\n","  File \"/usr/local/lib/python3.6/dist-packages/urllib3/response.py\", line 399, in _error_catcher\n","    self._connection.close()\n","  File \"/usr/lib/python3.6/http/client.py\", line 959, in close\n","    sock.close()   # close it manually... there may be other refs\n","  File \"/usr/lib/python3.6/socket.py\", line 417, in close\n","    self._real_close()\n","  File \"/usr/lib/python3.6/ssl.py\", line 1068, in _real_close\n","    socket._real_close(self)\n","  File \"/usr/lib/python3.6/socket.py\", line 411, in _real_close\n","    _ss.close(self)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5UDpEGjfO8Q2","colab_type":"code","outputId":"6f7b76b2-b1a5-4523-e819-33ce8c8a2ab6","executionInfo":{"status":"ok","timestamp":1582914231103,"user_tz":300,"elapsed":21273,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!python3 download_model.py 345M"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Fetching checkpoint: 1.00kit [00:00, 594kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 63.0Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 1.03Mit/s]                                                   \n","Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:18, 75.6Mit/s]                                 \n","Fetching model.ckpt.index: 11.0kit [00:00, 9.49Mit/s]                                               \n","Fetching model.ckpt.meta: 927kit [00:00, 54.1Mit/s]                                                 \n","Fetching vocab.bpe: 457kit [00:00, 48.9Mit/s]                                                       \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zq-YwRnNOBYO","colab_type":"text"},"source":["encoding"]},{"cell_type":"code","metadata":{"id":"7oJPQtdLbbeK","colab_type":"code","colab":{}},"source":["!export PYTHONIOENCODING=UTF-8"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0KzSbAvePgsI","colab_type":"text"},"source":["Fetch checkpoints if you have them saved in google drive"]},{"cell_type":"code","metadata":{"id":"cA2Wk7yIPmS6","colab_type":"code","colab":{}},"source":["!cp -r /content/drive/My\\ Drive/checkpoint/ /content/gpt-2/ "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vu5vKNhqdhDR","colab_type":"code","outputId":"7a020715-729f-4268-cf83-21a789706d95","executionInfo":{"status":"ok","timestamp":1582821001987,"user_tz":300,"elapsed":11715,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!PYTHONPATH=src ./train.py --help"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","usage: train.py [-h] --dataset PATH [--model_name MODEL] [--combine CHARS]\n","                [--encoding ENCODING] [--batch_size SIZE] [--learning_rate LR]\n","                [--accumulate_gradients N] [--memory_saving_gradients]\n","                [--only_train_transformer_layers] [--optimizer OPTIMIZER]\n","                [--noise NOISE] [--top_k TOP_K] [--top_p TOP_P]\n","                [--restore_from RESTORE_FROM] [--run_name RUN_NAME]\n","                [--sample_every N] [--sample_length TOKENS] [--sample_num N]\n","                [--save_every N] [--val_dataset PATH] [--val_batch_size SIZE]\n","                [--val_batch_count N] [--val_every STEPS]\n","\n","Fine-tune GPT-2 on your custom dataset.\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  --dataset PATH        Input file, directory, or glob pattern (utf-8 text, or\n","                        preencoded .npz files). (default: None)\n","  --model_name MODEL    Pretrained model name (default: 117M)\n","  --combine CHARS       Concatenate input files with <|endoftext|> separator\n","                        into chunks of this minimum size (default: 50000)\n","  --encoding ENCODING   Set the encoding for reading and writing files.\n","                        (default: utf-8)\n","  --batch_size SIZE     Batch size (default: 1)\n","  --learning_rate LR    Learning rate for Adam (default: 2e-05)\n","  --accumulate_gradients N\n","                        Accumulate gradients across N minibatches. (default:\n","                        1)\n","  --memory_saving_gradients\n","                        Use gradient checkpointing to reduce vram usage.\n","                        (default: False)\n","  --only_train_transformer_layers\n","                        Restrict training to the transformer blocks. (default:\n","                        False)\n","  --optimizer OPTIMIZER\n","                        Optimizer. <adam|sgd>. (default: adam)\n","  --noise NOISE         Add noise to input training data to regularize against\n","                        typos. (default: 0.0)\n","  --top_k TOP_K         K for top-k sampling. (default: 40)\n","  --top_p TOP_P         P for top-p sampling. Overrides top_k if set > 0.\n","                        (default: 0.0)\n","  --restore_from RESTORE_FROM\n","                        Either \"latest\", \"fresh\", or a path to a checkpoint\n","                        file (default: latest)\n","  --run_name RUN_NAME   Run id. Name of subdirectory in checkpoint/ and\n","                        samples/ (default: run1)\n","  --sample_every N      Generate samples every N steps (default: 100)\n","  --sample_length TOKENS\n","                        Sample this many tokens (default: 1023)\n","  --sample_num N        Generate this many samples (default: 1)\n","  --save_every N        Write a checkpoint every N steps (default: 1000)\n","  --val_dataset PATH    Dataset for validation loss, defaults to --dataset.\n","                        (default: None)\n","  --val_batch_size SIZE\n","                        Batch size for validation. (default: 2)\n","  --val_batch_count N   Number of batches for validation. (default: 40)\n","  --val_every STEPS     Calculate validation loss every STEPS steps. (default:\n","                        0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yPfJ5b3CQXqr","colab_type":"text"},"source":["\n","Start training, add --model_name '345M' to use 345 model"]},{"cell_type":"code","metadata":{"id":"pEn_ihcGI00T","colab_type":"code","outputId":"b2dd7b81-cafd-4c03-e54f-027fe9ff76c5","executionInfo":{"status":"ok","timestamp":1582772174022,"user_tz":300,"elapsed":39237,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!PYTHONPATH=src ./train.py --dataset \"/content/drive/My Drive/Chords and Devices for March EV show/feb 20 changes (added midi)/new-training-w-tempo expanded final.txt\" --sample_every 20 --sample_length 1023 --sample_num 10 --model_name '345M'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From ./train.py:88: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From ./train.py:91: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-02-28 04:16:18.278304: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2020-02-28 04:16:18.282492: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n","2020-02-28 04:16:18.282705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16a6f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-02-28 04:16:18.282734: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-02-28 04:16:18.296584: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-02-28 04:16:18.403525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-28 04:16:18.404200: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16a7100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-02-28 04:16:18.404234: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-02-28 04:16:18.404393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-28 04:16:18.404922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-28 04:16:18.405303: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-28 04:16:18.407169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-28 04:16:18.408993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-28 04:16:18.409512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-28 04:16:18.411431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-28 04:16:18.412243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-28 04:16:18.416072: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-28 04:16:18.416185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-28 04:16:18.416799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-28 04:16:18.417285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-28 04:16:18.417335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-28 04:16:18.418471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-28 04:16:18.418493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-28 04:16:18.418503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-28 04:16:18.418611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-28 04:16:18.419141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-28 04:16:18.419692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From ./train.py:92: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.random.categorical` instead.\n","WARNING:tensorflow:From ./train.py:117: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From ./train.py:121: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n","Instructions for updating:\n","Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n","WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:89: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From ./train.py:144: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","WARNING:tensorflow:From ./train.py:147: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n","\n","WARNING:tensorflow:From ./train.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","WARNING:tensorflow:From ./train.py:152: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From ./train.py:156: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","Loading checkpoint checkpoint/run1/model-1320\n","Loading dataset...\n","100% 1/1 [00:00<00:00,  1.33it/s]\n","dataset has 271937 tokens\n","Training...\n","2020-02-28 04:17:00.919259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","[1321 | 8.87] loss=0.27 avg=0.27\n","[1322 | 9.75] loss=0.26 avg=0.27\n","[1323 | 10.63] loss=0.21 avg=0.25\n","[1324 | 11.51] loss=0.45 avg=0.30\n","[1325 | 12.40] loss=0.20 avg=0.28\n","[1326 | 13.28] loss=0.21 avg=0.27\n","[1327 | 14.16] loss=0.30 avg=0.27\n","[1328 | 15.04] loss=0.22 avg=0.27\n","[1329 | 15.92] loss=0.20 avg=0.26\n","[1330 | 16.80] loss=0.18 avg=0.25\n","[1331 | 17.69] loss=0.25 avg=0.25\n","[1332 | 18.56] loss=0.20 avg=0.25\n","[1333 | 19.44] loss=0.15 avg=0.24\n","[1334 | 20.32] loss=0.29 avg=0.24\n","[1335 | 21.20] loss=0.46 avg=0.26\n","[1336 | 22.07] loss=0.11 avg=0.25\n","[1337 | 22.95] loss=0.21 avg=0.25\n","[1338 | 23.83] loss=0.33 avg=0.25\n","[1339 | 24.71] loss=0.23 avg=0.25\n","Generating samples...\n","======== SAMPLE 10 ========\n","cc iocac iocac iocac incbf incbf iqgba iqgaa iqgba isgae ipbaa ivbaj ivbaj iubag iubae ivbaj wubab iubae\n","imcac imcbc imcac ikcag iicae iocae incae iocdc imcdc imcad imcad ikcag iicae iocae iqcde ipcde\n","ipcac ipcbc ipcac ikcag iodae iodae iqdae ipdac iodbc ipdac ikcag ijdae iqdae iqdcd ipdcd\n","imcbc imcac ilcac imcag imcae imcae iobac iobbc iobac inaae ilaac ilaad imaad ilcad imbad\n","ipbac ipbac ipbac iobac iobae iqbae iqbac ipbac ipbac ipbad iqbac iqdad iqbcd irdcd\n","ipbac ipbac ipbac iobac iobae iqbae iqbac ipbac ipbac ipbad iqbac iqdad iqbcd ipdcd\n","ipbag ipbag iqbag iobag iobag iqbag ipbag ipbag ipbag iqbag iobag iqbag irbbg isbch isbch\n","ipbag iobag ilbag ilbag iqbag iqbag ipbag ipbag ipbag iqbag iobag iobag ipbbg ipbcg ipbcg\n","ipbaa iobaa ilbaa inbaa iqbaa iqbaa ipbaa iodaa itdaa ildaa irdaa iqdaa ipbda iodce iqdce\n","ilbaa imbaa ilbaa ikbaa ikbaa ikbaa ilbaa iobaa iobaa ilbaa ikbaa ikbaa inbba inbcc iobaj hwbaj\n","ipbaa iodaa ipdaa iqbaa iqbaa iqdac ipdac iqdaa ipdaa iqdaa irdaa irdaa iqbaa iqbba iqbca isbca\n","ipbaa iodaa ipdaa iqbaa iqbaa iqdac ipdac iqdaa ipdaa iqdaa irdaa iqdaa iqbaa iqbcb irbcc irbcc\n","ipbaa iodaa ipdaa iqbaa iqbaa iqdac ipdac iqdaa ipdaa iqdba iqdca iqdab iqgab iqbab iqgab iqgab\n","iqgaa iqgaa iqgaa iogaa iogaa iogac ipgae ipgae isgaa isgaa iugaa iqgab isgab iugab iubab itgab\n","irgaa iqgaa iqgaa iodaa iodaa iodac ipdac ipgae iqgaa iqgaa iqgab ipdae iodae irgac isgaa iugaa\n","imgaa imgaa imgaa imgaj imgaj imgaj ikgaj ikgaj imgaa imgaa imgaa imgaj imgaj imgac iogab iqgab ipgab\n","imgaa imgaj imgaj imaaj ikaaa ikaaa ikaaa imgaa imgae imgae incaa imgae incaa iogac iqgac iqgaa iqgaa\n","iogaa iogaj iogaj imgaj ilaaa ilaaa ilaaa iogai iogai ipgai ipgac iqgai iqgac irgaa iqgaa ipgaa\n","imgaf imgaj imgaj imaaj ilaaa ilaaa ilaaa imgai imdai ildai imdac imgai ildai imgac iogab iqgab iodab\n","ildaf ildaj ildaj imdaj ikdaf ikdaj ikdaj ijdai ijdai ildai ildac ildaj ikdaj ikdcf imgcj iogcj\n","imgai imgai imgai imgai iogai iogai iogai iogai imgai imgai imgai imgac ikdai ikdbi \n","\n","[1340 | 203.44] loss=0.20 avg=0.25\n","[1341 | 204.32] loss=0.18 avg=0.24\n","[1342 | 205.20] loss=0.19 avg=0.24\n","[1343 | 206.07] loss=0.19 avg=0.24\n","[1344 | 206.95] loss=0.21 avg=0.24\n","[1345 | 207.83] loss=0.22 avg=0.24\n","[1346 | 208.71] loss=0.20 avg=0.23\n","[1347 | 209.58] loss=0.14 avg=0.23\n","[1348 | 210.46] loss=0.15 avg=0.23\n","[1349 | 211.34] loss=0.40 avg=0.23\n","[1350 | 212.22] loss=0.22 avg=0.23\n","[1351 | 213.09] loss=0.26 avg=0.23\n","[1352 | 213.97] loss=0.22 avg=0.23\n","[1353 | 214.85] loss=0.19 avg=0.23\n","[1354 | 215.73] loss=0.18 avg=0.23\n","[1355 | 216.61] loss=0.38 avg=0.24\n","[1356 | 217.49] loss=0.13 avg=0.23\n","[1357 | 218.37] loss=0.23 avg=0.23\n","[1358 | 219.25] loss=0.16 avg=0.23\n","[1359 | 220.12] loss=0.18 avg=0.23\n","Generating samples...\n","======== SAMPLE 10 ========\n","gcag iccag ihcag iicag ihcag iccag iicag ihcag iicag iicag iicbg iricc irccb ircai iugag iugag ipgag irgag irgbi itgcd itcag iugag iwgag\n","imgag ikgaa ilgaa ijgaa imgaa iogaa ikgaa ilgaa ijgaa ikgaa ipgaa iogaa imgaa iogaa ipgbg irgag iugag\n","imgai imgai iogai iogai imgae imgae ikgae ikgaa iogaa imgaa ipgaa ilgaa imgae iogbe iqgce irgae iogae\n","imgab imgab iogab iogab imdae imdae ikdae ildab ijdab ikdab ioddb iodcb iodac iqgac iogab itgab\n","iodab iodab ipdab ipdab indae indae iqdab iodab ipdab ipdab iqdab ipdab ipdbb itdac itgac itdac\n","ipdab ipdab ipdab iodab iodae indae irdab ipdab ipdab iodab iodab irdab irdab ipdbb iqgcc iugac itgac\n","imgaf imgaf imgae imgae imdae ikdaf ikdaf irgaf irgaf iugaf iugaf imgae imgae imdbe imgce iogae iogae\n","imgaf imgaa ikgaa imgaa imdae ikdae ikdaa iidae ijdaa iodaa imdaa ikdaa imdba iodca iodaa iogaa irdaa\n","ipdaf ipdaf iqdaf iqdaf iodae iodae ipdae iqdaf indaf indaf ipdaf ipdbf iqgcf iqdaj irdaj irdaa isdaa\n","iogaj iogaj iqgaj iqgaj iodaj iodaj iodaj imgaj ilgaj ilgaj iogaj iogai imgaj ipgah irgah\n","imgab imgae ikgae ikgae imgae imdae ikdae imgae imgae ipgab ipdae indae ipgcf iqgaf iugab iugab\n","ipdab ipdbb ipdab iodaa imdaa ikdca ipdab ipdab irdab isdab irdab isdab iudca iudca iqgac iugab itgab\n","irdab irdbb irdab itdaa iqdaa iqdca irdab irdab iudab isdab irdab isdab iudca iudca iqdaf iudaf itdaf\n","itdaf itdaf itdaf itdaf iudaf iudaf isdaf irdaf irdaf itdaf itdaf itdaf itdaf iudcf iudcf iwdag iwdag\n","iqdah iqdag ipdai iqdai iodai iodci isdai isdag irdah irdai iudag isdah isdag iudai iudci ivdag itdag\n","iqdah ipdag irdai iodai iodai iodci ipdag irdah irdag iudah iudag iqdah iqdbj irdca isdca irdaj iudaj\n","iqdaf ipdag irdai iodai iodai iodci ipdag irdaf irdag iudag iqdag iqdbj ipdca irdca iqdaj iodeaj\n","iodaf ipdah irdai iodai incdci ipdah irdah iodag ineaf ineaf ipeah ioech imcah incch ipcch\n","iqdaf ipdaf irdaf iodaf incdaf ipdaf irdaf ipdbf imdaf ipdaf ipdbf iqdaf iqdbf irfcg iscag iscag\n","itcaf itcaf itcaf itcaf ircaf ircaf itcaf itcaf iucaf iucaf itcaf itcaf iucaf iucbf ivccf ivcag ivcag\n","itcaf itcaf ircaf\n","\n","[1360 | 395.60] loss=0.17 avg=0.23\n","[1361 | 396.48] loss=0.20 avg=0.23\n","[1362 | 397.36] loss=0.15 avg=0.22\n","[1363 | 398.23] loss=0.29 avg=0.23\n","[1364 | 399.11] loss=0.19 avg=0.22\n","[1365 | 399.99] loss=0.17 avg=0.22\n","[1366 | 400.88] loss=0.16 avg=0.22\n","[1367 | 401.75] loss=0.19 avg=0.22\n","[1368 | 402.64] loss=0.24 avg=0.22\n","[1369 | 403.51] loss=0.16 avg=0.22\n","[1370 | 404.39] loss=0.15 avg=0.22\n","[1371 | 405.27] loss=0.16 avg=0.22\n","[1372 | 406.14] loss=0.31 avg=0.22\n","[1373 | 407.02] loss=0.14 avg=0.22\n","[1374 | 407.90] loss=0.19 avg=0.22\n","[1375 | 408.77] loss=0.13 avg=0.21\n","[1376 | 409.65] loss=0.22 avg=0.21\n","[1377 | 410.53] loss=0.16 avg=0.21\n","[1378 | 411.41] loss=0.34 avg=0.22\n","[1379 | 412.28] loss=0.28 avg=0.22\n","Generating samples...\n","======== SAMPLE 10 ========\n","d ixdah ivdah ivdah iwdah iwdac ixbcb ixbcb\n","ifcaa ifcaa igcaa igcaa iicaa iicaa ihcaa iecaa iccaa icaa icaa ihcaa igcaa igcca ihcca\n","ifcaa icaa ikcaa ikcaa ifcaa icaa ikcaa iecaa icaa ikcaa ikcaa ijcba ihcba igcaa ikcaa\n","ihdaa ihdaa ijdaa ijdaa igdaa igdaa igdaa ijdaa ijdaa ijdaa ikdaa ihbaa igbaa igdaa ihdaa\n","ijcad ijcad ilcad ilcad ijcad iicaad ihcad igcad iicad iicad imcad ikcad ikcbd ilacd ikcad\n","iicad ikcad ijcad ijcad ikcad ikcad ihcad ikcad ikcad ipcad ijcad iicad ijcbd ikccd ilcad ikcad\n","iicad ihcad ijcad ihcad ikcad ikcad ikcad ipcad ipcad ijcad ijcad ijcad ijcad ikcbd ikccd ilcad\n","iicag ihcag ijcag igcag ikcag ikcag ihcag igcag iicag ikcag ilcag ijcag iicag ikcag ilcbg imcag iocag\n","ihcag ihcag igcag ikcag ihcag ihcag ikcag ihcag ingag incag imcag incag incag iocbg ioccg iocag\n","ijcab ijcab ikcab iicab iicab ijcab iicab ingab imcab ikcab ikcab iocab iocab iocbb ipccb ioccg incag\n","ilcab ikcab ijcab ikcab imcab ikcab ilcab ijcab iicab igcab ikcab ijcab ijcab ikcbb ilccb ilcag imcag\n","ijcab ijcbb ijcab iicab iocab iocab iocab incab imcab ikcab ijcab ijcab ikcab iocbb ioccb iocag incag\n","ikcab ikcbb ikcab iicac ijcac ijcac ikcac imcac ikcab incac incac iocac imcac ikcab ikcbb ikccb ilcag incag\n","ijcbe ijcae ikcag ijcag iicag iicag ilcae ijcae imcag ikcae ikcac ijcac iicac iicbb ihcce imgce\n","ijcae ijcae iicag ikcag iicag ikcag ilcae ijcae iicae ijcac ijcaf iicaf iobaf incbf inccg incag iocag\n","iocaa iocaa ipcaa incaa ipcaa incaa ilcaa iqcaa iocaa iocaa incaa ircaa iocdc ipcca ircaa iqcaaa\n","ipcaa iocaa ipcaa imcaa ipcaa ipcaa ilcaa iqcaa iocaa ipcaa iocaa ipcaa iqcaaa ircba ircca iqcaa\n","incaa imcaa imcaa ikcaa incaa imcaa ilcaa ipcaa incaa incaa ipcaa ipcaa iqcaaa ircba ircca iocaa\n","ijcae ijcae ikcae iicae iicae iicae iqcae ipcae ircae ircae iscae iscae iocae iocbe ipcce iocce\n","imcae ikcae iicae ikcae imcae ikcae ilcae incae ircae ircae iscae ircae iscae iocbe iocce i\n","\n","[1380 | 589.31] loss=0.25 avg=0.22\n","[1381 | 590.19] loss=0.16 avg=0.22\n","[1382 | 591.06] loss=0.14 avg=0.21\n","[1383 | 591.94] loss=0.25 avg=0.22\n","[1384 | 592.82] loss=0.22 avg=0.22\n","[1385 | 593.70] loss=0.15 avg=0.21\n","[1386 | 594.57] loss=0.17 avg=0.21\n","[1387 | 595.45] loss=0.21 avg=0.21\n","[1388 | 596.32] loss=0.17 avg=0.21\n","[1389 | 597.21] loss=0.23 avg=0.21\n","[1390 | 598.08] loss=0.15 avg=0.21\n","[1391 | 598.96] loss=0.17 avg=0.21\n","[1392 | 599.84] loss=0.13 avg=0.21\n","[1393 | 600.72] loss=0.17 avg=0.21\n","[1394 | 601.59] loss=0.21 avg=0.21\n","[1395 | 602.47] loss=0.14 avg=0.21\n","[1396 | 603.35] loss=0.18 avg=0.21\n","[1397 | 604.23] loss=0.13 avg=0.21\n","[1398 | 605.11] loss=0.20 avg=0.21\n","[1399 | 605.99] loss=0.20 avg=0.20\n","Generating samples...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vS1RJJDFOPnb","colab_type":"text"},"source":["Save our checkpoints (and samples) to start training again later"]},{"cell_type":"code","metadata":{"id":"JretqG1zOXdi","colab_type":"code","colab":{}},"source":["!cp -r /content/gpt-2/checkpoint/ /content/drive/My\\ Drive/\n","!cp -r /content/gpt-2/samples/* /content/drive/My\\ Drive/gpt2samples/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6D-i7vERWbNS","colab_type":"text"},"source":["Load your trained model for use in sampling below (117M or 345M)"]},{"cell_type":"code","metadata":{"id":"VeETvWvrbKga","colab_type":"code","outputId":"f31b613c-2e72-4c72-8a6b-d192b8094e9c","executionInfo":{"status":"ok","timestamp":1582792012757,"user_tz":300,"elapsed":1440,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/117M/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cp: cannot stat '/content/gpt-2/checkpoint/run1/*': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"np0r6qfXBeUX","colab_type":"code","colab":{}},"source":["!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/345M/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GmnSrXqtfRbq","colab_type":"text"},"source":["Generate conditional samples from the model given a prompt you provide -  change top-k hyperparameter if desired (default is 40),  if you're using 345M, add \"--model-name 345M\""]},{"cell_type":"code","metadata":{"id":"utJj-iY4gHwE","colab_type":"code","outputId":"897ca958-6838-4b80-a194-d1b391acb840","executionInfo":{"status":"ok","timestamp":1582791785985,"user_tz":300,"elapsed":208,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python3 src/interactive_conditional_samples.py --top_k 40 --model_name \"345M\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","WARNING:tensorflow:From src/interactive_conditional_samples.py:55: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-02-27 02:56:28.860189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-02-27 02:56:28.900275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-27 02:56:28.900951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-02-27 02:56:28.901412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-27 02:56:28.902996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-27 02:56:28.904433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-27 02:56:28.904761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-27 02:56:28.906102: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-27 02:56:28.906796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-27 02:56:28.909851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-27 02:56:28.910005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-27 02:56:28.910637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-27 02:56:28.911191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-27 02:56:28.916077: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-02-27 02:56:28.916243: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c55100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-02-27 02:56:28.916267: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-02-27 02:56:29.024090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-27 02:56:29.024744: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c552c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-02-27 02:56:29.024778: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-02-27 02:56:29.024970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-27 02:56:29.025473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-02-27 02:56:29.025595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-27 02:56:29.025638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-27 02:56:29.025661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-27 02:56:29.025681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-27 02:56:29.025700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-27 02:56:29.025718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-27 02:56:29.025737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-27 02:56:29.025833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-27 02:56:29.026656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-27 02:56:29.027180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-27 02:56:29.027245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-27 02:56:29.028459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-27 02:56:29.028485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-27 02:56:29.028496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-27 02:56:29.028704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-27 02:56:29.029345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-27 02:56:29.029940: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-02-27 02:56:29.029983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From src/interactive_conditional_samples.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.random.categorical` instead.\n","WARNING:tensorflow:From src/interactive_conditional_samples.py:66: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","Model prompt >>> imcaa\n","2020-02-27 02:56:55.561655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","======================================== SAMPLE 1 ========================================\n",". \"What's next?\"<|endoftext|>Singer and songwriter David Bowie was born Anthony Harvey in London. He is of British and French heritage. Bowie received his JCAB-certification (\"Bard of the Year\" honors) in 1996 and has performed in Britain and America and abroad since 1990. Born in London in January 1943, Bowie moved to a hostel while in school, graduating in 1948. In 1952 Bowie took up dance training in Birmingham and taught himself how to perform guitar from his childhood idol Eddie Cochran. The results of his training were incorporated into the album of the same name to which he became the principal singer and songwriter. Following the birth of his child, Bowie decided to relocate to New York in order to pursue a further education. During this time, Bowie and his wife, Julie, began work together on a number of songs which were eventually released on the album The Man Who Fell To Earth in 1970. Bowie's early solo albums included Live at the Apollo, Born On A Beach, and Bowie's own solo album The Man Who Fell To Earth, which he composed and performed as an ensemble. Bowie's solo career took off during the 1960s and, while still not his first solo album, was a highly successful one, with the singles \"Blackstar\", \"Satisfaction\" and \"Blackstar\" becoming well known among the music press. Bowie's solo career was further strengthened by working with his son in the songwriting process. The latter was the lead vocalist for the late Brian Eno's band the Orb, and the latter his second singer-songwriter. As a result, Eno was able to take some of his influences from Bowie's music and to create his own unique and original material. In 1966, Bowie formed his own band, the Mercury Revue, which included Eno, and they released his breakthrough album A Night To Remember, which included the single \"Under Pressure\". He also wrote and performed several covers of classic album-of-the-year songs, including \"I Saw Her Dance\", \"Taurus (In The Night)\" and \"She's Gone\". Bowie was invited to sing in the 1967 Summer Olympics, which he did a few years later. After the concert, he went into recording mode and, after touring only briefly, released solo albums again. He would compose new material for them in the subsequent decades but never played. Bowie's last album, 2001's Human Be-in'-Her-Head, came out in 2002. His final single, \"We're Never\n","================================================================================\n","Model prompt >>> \n","Prompt should not be empty!\n","Model prompt >>> imcaa\n","======================================== SAMPLE 1 ========================================\n"," and Erythropoda (Lissner et al., 2007) and in two species of the giant squid (Thrachoplodon rutigeri and Stylophora caeruleus) (Dawkins, 1989; Molloy et al., 2015). The relative proportions of the three taxa increased at different points during the Paleocene–Eocene Thermal Maximum in western North America in response to anthropogenic effects, including the widespread presence of human artifacts (Kuhn et al., 2001). The largest relative increase occurred among the four species studied and the lowest among three. In addition, among the species studied the largest relative decrease can be found among the T. rutigeri species (the lowest among the three is T. caeruleus).\n","\n","This analysis supports the idea that the observed trends towards increases in the size range of fossil taxa of the modern western North Americas can be explained mainly by increased levels of anthropogenic fossil deposits (McQuaid and Molloy, 2007). The highest rates of accumulation are associated with human artifacts (McQuaid and Molloy, 2007; Boulton et al., 2012; Schiller et al., 2013) and the earliest estimates place these as being approximately 7.5 Ma (Schiller et al., 2013). These estimates, based on estimates of radiocarbon ages of ∼2.0 Ma, could correspond to a rate of change of ∼2 Ma/yr (Chua et al., 2017). The rate of change in T. caeruleus is much smaller than for T. rutigeri because the species is only known from rocks deposited about 5 Ma (Chua et al., 2017). The fossil record therefore offers limited help to constrain the evolution of the fossil records in western North Carolina. However, a few additional constraints on the fossil record in this part of the United States can further aid understanding the rate and timing of the evolution of the present fossil record.\n","\n","Anthropogenic fossil deposits in western North Carolina\n","\n","The vast majority of fossils unearthed in western North Carolina are the remnants of terrestrial vertebrate or amphibian skeletons of an old age. The age of some of these remains are as old as ∼6.4 Ma (McQuaid and Molloy, 2007; Davies et al., 2008; McCracken et al., 2010). Some individuals are of recent origin (Spencer et al., 2012) which suggests an earlier human introduction into western North Carolina than previously suggested. In general\n","================================================================================\n","Model prompt >>> tell me something good\n","======================================== SAMPLE 1 ========================================\n",".\"\n","\n","\"This song is just as important as anything else because everyone loves you, not because of how good you're supposed to be at it. Even though you're playing really bad music you're still someone.\"\n","\n","And then his son turned to me and said \"Mom, you know this guy is really nice. He makes my dreams come true. He takes me where I need to go.\"\n","\n","I had been looking out of the window just a little too hard, watching the sky, but I knew he was talking about his brother.\n","\n","What I have found in my life is that even though every single thing is so perfect or all of the girls in the world are in bed with you, you know you're the best.\n","\n","Even if you're in hell.<|endoftext|>Sidewalk, Walkway, and Paths\n","\n","We offer the full range of services including sidewalk, walkway, and path maintenance, snow removal, and flood monitoring in downtown Seattle and surrounding neighborhoods. We will also provide transportation for you and your family to and from work, school, and other events at the intersection of Northlake and Pinehurst.\n","\n","We accept sidewalk/path maintenance and snow removal, snow removal and recovery, and flood monitoring. We also provide street sweeping service.\n","\n","Our work isn't over at some point. We welcome suggestions for further work, or you can talk with a knowledgeable service provider directly.\n","\n","We can also provide water/ice clean-up.<|endoftext|>The World Health Organization announced on Sunday that Zika is \"definitely\" a causative factor for a deadly birth defect called microcephaly, now in the news, and may also affect newborn babies in the United States. If true, it could change the debate over the health risks posed by Zika to expectant moms and fathers, the WHO warned.\n","\n","Microcephaly is a birth defect of the developing brain and sometimes associated with cerebral palsy. It is the most common neurological disorders in the United States, affecting between 13 and 25 percent of all births of babies in the United States, according to the latest findings of the National Center for Health Statistics, a joint partnership of the National Institutes of Health and the Centers for Disease Control and Prevention. A 2012 analysis of microcephaly cases and deaths in the United States found that between 8,900 and 9,500 babies may be affected by a microcephaly condition, of which approximately 3,900 to 5,900 were born with Zika at the start\n","================================================================================\n","Model prompt >>> Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n","    self.gen.throw(type, value, traceback)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 5480, in get_controller\n","    yield g\n","  File \"src/interactive_conditional_samples.py\", line 71, in interact_model\n","    raw_text = input(\"Model prompt >>> \")\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"src/interactive_conditional_samples.py\", line 89, in <module>\n","    fire.Fire(interact_model)\n","  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n","    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n","  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n","    target=component.__name__)\n","  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n","    component = fn(*varargs, **kwargs)\n","  File \"src/interactive_conditional_samples.py\", line 86, in interact_model\n","    print(\"=\" * 80)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1634, in __exit__\n","    close_thread.join(30.0)\n","  File \"/usr/lib/python3.6/threading.py\", line 1060, in join\n","    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n","  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n","    elif lock.acquire(block, timeout):\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LeDhY97XMDXn","colab_type":"text"},"source":["To check flag descriptions, use:"]},{"cell_type":"code","metadata":{"id":"pBaj2L_KMAgb","colab_type":"code","colab":{}},"source":["!python3 src/interactive_conditional_samples.py -- --help"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K8rSqkGxg5OK","colab_type":"text"},"source":["Generate unconditional samples from the model,  if you're using 345M, add \"--model-name 345M\""]},{"cell_type":"code","metadata":{"id":"LaQUEnRxWc3c","colab_type":"code","outputId":"d57c62b0-f390-4293-ddad-47890ee84f5a","executionInfo":{"status":"ok","timestamp":1582917400175,"user_tz":300,"elapsed":1530958,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python3 src/generate_unconditional_samples.py --model_name \"345M\" --temperature=0.5 | tee -a \"/content/drive/My Drive/gpt2samples/newSamples.txt\""],"execution_count":11,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aadaf\n","\n","aad\n","======================================== SAMPLE 35 ========================================\n","aabab aabab aabab aabab abcab abcab abcab abcab abcab abcab abcab abbab abbbb abbcc afbab ifabb ifabg ijfab ijfab\n","iifab ihfab ihfab ijfad iifad ihfad ijfad ilfad infad ilfad ijfad iifad ihbdb ijfcd ikfad ilfad\n","ihfab ihfab ikfab ikfad ijfad ijfad ikfad infab infab infab ijfab ihbab ihbdb ijfcd ijfad ijfad\n","ikfab ikfab ikfab ijfad ijfad ijfad ikfad infab ikfab ikfab ikfab infab iofbb iofch iofag iufag\n","ikfag ikfag ikfag ijfae ijfae ijfae ijfae ikfag ikfag ikfag ikfae ikfae ikfae ilfae ilfae\n","iifag ihfag ikfag ijfah iifah iifah ihdah imdag iodag iodag imdag imfah ikdag ikdbe imfce iufae iufae\n","ihfae ihfae ikfae ijfae ijfae ijfae ihdae imdae ildae ildae ijdae ikfae imfah imfah imgab iofab\n","ikfaf ikfaf ijfaf ijfaf ilfah ikfah ijfah ikfag infaf infaf ikfah ikfag imdaf imdaf imfba iofaa iofaa\n","ijfaf ijfaf ijfaf ihfaf ihfah iifah iifah ijfag ijfaf ijfaf ijfaf ijfah ikfaf ikfbh ikfci ikfai ijfai\n","ikfaf ikfaf ijfaf ihfaf ihfah iifah iifah ijfag ijfaf ijfaf ijfaf ijfah ikfaf ikfbh ikfch ikfai ijfai\n","ijfaj ijfaj ikfaj ijfaa iifaa iifaa iifaa ijcaj iicaj ikcaj iicaa ikcaa ihcaj ijcaa ijcah ikfah\n","ikcaj ikcaj ijcaa iicaa iicaa iicaa ijcaj iicaj imcaa imcaa ikcaa ikcaj ijcab ijdab iocah imfah\n","infaj infaj iobaj iobaa ipbaa ipbaa iqfaj iifaj iifaj imbaa imbaa ilfaj ilfbh infag ipfag\n","ijfab ijfaf ijfaf ijfaf ilfaf ilfaf ikfab ikfaf infaf infaf ikfah ikfab ikfag infah iofah\n","imfaf imfaf imfaf ikfaf ikfaf ileaf ileaf imeaf imeaf imaaf imabf imecf imaaf ioaaf iofaf\n","ikfaf ikfaf ikfaf ijfaf ijfaf ijfaf imeaf imeaf ikfaf ikfah ikfaf imfag imdag imfad iofad\n","ifaag ifaaf ifaaf ihaaf ihaaf iheaf igeaf igeaf ifeaf ifeaf igeaf igeah ifeag igeag iheag\n","ikaaa ikaaa imaaa imaaa imeaa imeaa ileaa ileaa imeaa imaaa imaaa imaaa imaah imeag imebg imaaa iqaaa\n","inaaa imaaa ikaaa ioaaa inaaa imaaa ilaaa ioaaa imaaa ikaaa inaaa ioaaa inaaa ipaah ipfah ipaaa\n","inaaa imdaa ikdaa ioaaa iniaa imeaa\n","======================================== SAMPLE 36 ========================================\n","a\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","ab\n","\n","baiab\n","iabai\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabaj\n","\n","iabbj\n","\n","iabik\n","\n","iabbj ihcaj ihcaj ijcaa ijcaa iocaj iocaj ipcaj ipcaj ipcaj iqcbj iqccj irccj\n","iocaj iocaj ipcaj ipcaj iqcaj iqcaj iscaj iscaj itcaj itcaj ircbj irccj irccj\n","iscaj iscaj iqcaj iqcaj ircaj ircaj iscaj ircaj itcaj itcaj ircaj ircbj irccj ircaj ircaj\n","ircaa ircaa itcaa iucaa ircaa ircaa iocaa itcaa iscaa ivcaa ivcaa itcaa iucba iwcaa\n","itdaa itdaa iudaa iudaa isdaa isdaj iudaj ivdaa ivdaa ivdaa itdaa itdaa itdaa ivdba ivdca ivdaa\n","irfaa irfaa irfaa ircaa irfaj irfaj iufaj iufaa irfaa irfaa irfaa itfaa itfaa ivfba ivfca ivfaa\n","irfaa irfaa iqfaa iqfaa irfaj irfaj iufaj iufaa irfaa irfaa iqfaa iqfaa irfba irfca irfaa irfaa\n","iqcac iqcbc iqcac iscag iqcag irccg ipcag ipcag iscag iscag iqcag iocbg iqgcg iscaa ircaa\n","iqcbf iqcaf ipcah iqcah iqcch ipcah ipcah iscaf iqcaf iocaf iqfcf isfcf iscag iqcag iqcaa ipcaa\n","iocac iocaf incah iocah iqcch ipcah ipcah iscaf iqcaf iocaf iqfcf irfcf isfag iqbag iqcag\n","isfac isfaf iqcah iscah iscch iqcah iqcah isfaf itfaf itfaf iufaf iqfcf irfcf irfag iqbag iqfag\n","iqfag iqfag iqfag iqfag isfag isfag isfag isfag iqfag iqfag iqfag isfag isfag iufag irfag\n","ipaag ipaag ipaag iraag iraag iraag ipaag ipaag iraag iraag isaag isaag itaag itabc irabc\n","iqaae iqaae isaae isaae iqaae iqaae iuaae iuaae itaae itaae itaae iuaae iuabd iuacd iuaad ivaad\n","irae irae iqaae iqaae isae irae irae\n","======================================== SAMPLE 37 ========================================\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dafaa\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","dcfj\n","\n","hdce\n","\n","hdce\n","\n","ihcah\n","\n","ihcah\n","\n","ihcah\n","\n","ihcah\n","\n","ihcah\n","\n","ipbah\n","\n","ipbah\n","\n","ipbah\n","\n","ipbah\n","\n","ipbaa\n","\n","ipbaa\n","\n","ipfaa\n","\n","iqfaa\n","\n","iqfaa\n","\n","iqfaa\n","\n","riaa\n","\n","riaa\n","\n","riaa\n","\n","siabf siabf\n","\n","siabf siabf\n","\n","tahaf toaah toaah toaah tohcg tohaf ircaf ircaf itcaf itcaf iqcaf iqcbf itccf iuccf\n","itdaf itdaf\n","ipdaf ipdaf iqdaf iqdaf iqdaf isdaf isdaf itdaf itdaf iqdaf iqdaf iqdaf irdaf irdbf isdcf isdcf\n","ircaf ircaf\n","iqcaf ircaf iqcaf iqcaf iqcaf iscaf ircaf ircaf iqcaf iqcaf ircaf iocaf itcbf itccf itcaf iscaf\n","ipcaf ipcaf\n","iqcaf ipcaf iqcaf iqcaf iqcaf iscaf ipcaf ipcaf iqcaf iqcaf ipcaf iocaf itcbf itccf itcaf iscaf\n","iocaj iocai iocai imcaa imcaa ipdaa iqdaa ircaa ircai ircai iucaa iqdaa iqcaa iscaa\n","ircah ircag imcag iqcaa ipdaa ipdag irdag isdag iscag ircag iocag ipcbf iuccf iuccf\n","isaah isaah itaah itcaa iqdaa iqdah ihdag irdag irdag ivdah ivdag ipdag ipdbh irdch irdch\n","itdah itdah itdah iudah iudah iudah itdah itdah itdah ivdah ivdah ivdah iwdbh iwcah iwcah\n","ircaf ircag imcag iqcaa ipdaa ipdag irdag irdag itdag ircag ircaf irgac itdaa itgah iteah\n","irgaf irgaf irgaf irgaf itgaf itgaf itgaf irgaf irgaf irfaf irfaf itfbf itfcf ivfaf ivfaf\n","ipfaf ipfaf ipfaf irfaf irfaf irfaf iqfaf iqfaf ipfaf ipfaf ipfaf irfaf irfbf itfaf itfaf\n","ircaf ircaf ipcaf iqcaf ircaf ircaf ircaf iscaf iscaf ircaf ipcaf iocaf ipcbf iqfaf iqfaf\n","irfaj irfaj irfaj irgaj irgaj ircaj ipcaj iscaj iscaj ircaj irfaj irfaj irfaj itfaj itcaj iucaj\n","ipcaj ipcaj ipcaj iqcaj iqcaj iqcaj ircaj iscaj iscaj ipcaj ipcaj iqcaj iqcaj ircbj iscaj iscaj\n","iocad imcah imeah imcah iocag iocag ipcah iscah iscah iocad iocah ipcah ipc\n","======================================== SAMPLE 38 ========================================\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","iie\n","\n","ihd\n","\n","ihd\n","\n","ihd\n","\n","ihd\n","\n","ihd\n","\n","ihd\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","ije\n","\n","ije\n","\n","ije\n","\n","ije\n","\n","ije\n","\n","ilh\n","\n","ilh\n","\n","ilh\n","\n","ilh\n","\n","ilh\n","\n","ilh\n","\n","ipd\n","\n","ipd\n","\n","ipd\n","\n","iqaa iqaa iqaa iqaa iqaaa iodaa indaa indaa indaa ingaa ipgaa iqgaa irgaa irgaa\n","ihda ihdg ihdg ifgj ijdj ihdj ihdj ijdg igdg ifdg ifdg iidg ijdg iidg ildj ildj imdbj indbj\n","ifdaj ifdaj igdaj iedaj iedaj iedaj iddaj ifdaj ifdaj iddaj iedaj iedaj igdj ijdcj ijdcj\n","ifdah ifdah iddah iedah iedah iedah iddah ifdah iddah iedah iedah igdah ijdbh ijdch ijdch\n","iddah iddah idaah idaah idaah idaah idaah iddah iddah idaah idaah iedbj iedcj iddaj idaj\n","ifgab ifgab ihgab ijgab ifgab ifgab ihgab ijgab iigab ifgab iigab ijgab ijgbb imgcb iggab iigab\n","ihgab ihgab iggab iggab ihgab ihgab ihgab iigab iggab iggab ikgab ikgbb imgcb imgab ihgab\n","ihgab ijgab iggab ikgab iigab iigab ihgab ikgab iggab iigab ikgab ihgbb iggcb ihgac ihgac\n","ikgab ikgab iigab iigab ikgab ikgab ilgab ikgab iigab iigab iigab ikgbb ikgcb ilgac il\n","======================================== SAMPLE 39 ========================================\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","abcd\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aadc\n","\n","aad\n","======================================== SAMPLE 40 ========================================\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","ae\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","ae\n","\n","iie\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","ihe\n","\n","iie ijeah ijeah ijeah ilch ijeah ijeah ikch ijeah ihch ijch\n","iie ijeah ijeah ikfaj ijfaj ijfaj ilfaj ikfaj ijeah ilfah ijfah ikfah ilfah ilfbe imfce\n","ilfah ilfah ikfaj ijfaj ijfaj ijfaj ilfaj ikfah ikfah ikfah ikfah ikfah imfah imfbe iofce\n","ikfah ikfah ijfaj ijfaj ijfaj ijfaj ikfah ikfah iikfah iikfah ijfah ijfah ijfah imfah imfbe iofce\n","ijdah ijdah ijfaj ihdaj ihdaj iidah iidah ikdah ijdah ijdah iidah ikdah ikdah ildah imdah\n","ifdah ifdah iddaj iddaj iddaj icdah icdah iddah iddah iddah iddah iidah ihdah iidbh ijdch ijdch\n","ijdah ijdah ijfaj ihdaj ihdaj iidah ikdah ikfah iifah iifah ijfah ijfah ildah imfah ildah\n","ifaah ifaah iddaj iddaj iddaj icdah ikdah ikfah iffah iffah iddah iddah ildah imfah ildah\n","iifah iifah iddaj iddaj iddaj icdah ikdah ikfah iffah iffah iddah iddah ildah im\n","======================================== SAMPLE 41 ========================================\n","e ][ h ESL One Katowice 2015 League Information Organizer: ESL Type: Online Location: Katowice, Poland Sponsor: Intel Sponsor:\n","\n","[IMG] eiie ijfie ijfce ijfai ilfai ikfai ijfai ikfai ijfai ijfai ijfai ijfai ijfai ijfbi jfci ijfci ijfci\n","infac infac iqfad iqfad iqfad irdad ipfad infad ipfad isfad iqfad iqfad isfbd itfcd itfad\n","iifac iifac ijfad ijfad ijfad ikfad ikfad iifad iifac ikfad ijfad ijfac ikfbd ilfcd ilfad infad\n","iifaf ihfaf ikfae ikfae ikfae ihcae ihcae iifah ihfah ilfae ijfae ikfae ilfbe ilfce ihfaf ikfaf\n","iifaf iffaf ikfae ijfae ijfae ikfae ikfae ikfah ikfah ilfae ijfae ikfae ilfbe ilfce ilfaf ikfaf\n","iibai ihbai ikbai ijbai iibai ihbai ihcai iicah iicah ikcai ijcai iibai iicbi ijcci ijbai iibai\n","ikbai ikbai ijbai ijfai ikfai ikfai iifah iifah ikfai ijfai ijbai ikbai ikbbe ilbce ilbai ilbai\n","iibag ihbag ijbag iibaj ihbai ihbaj ikbaj imbah iibaj ikbag iibag imbag imbaa iobai ikbag iibag\n","iibaj ihbaj ijbaj ikbaj ilbaj ilbaj ikdah ihdaj ikdaj iibaj iibaj ijbaa ikdaj ilbaa ikbaj\n","ijfaj ijfaj ijfaj ijfaj iifaj iifaj iifah iifaj iifaj iifaj ijfaa iifah ijfah ikfah\n","ifaaa ifaaa igaaa igaaa ihaaa ihfaa iifaa ikfaa ikfaa iffaa iffaa ikfba ikdaf ikdaf\n","ikfaa ikfaa ikfaa iifaa iifaa iifaa ihfaa ikfaa ikfaa ikfaa ikfaa ikfba ilfaf ilfaf\n","iifaf ihfaf igfaf igfaf iifaf ihfaf ihfaf ikfaf ikfaf iifaf iifaf iifaf ikfaf ikfbh ilfah infah\n","ijfaf ijfaf ijfaf ihdaf ihdaf iheaf ijeaf ijeaf ijeaf ijead iieaf iieaf ijead ikead ikead\n","ifaah ifaaf ifaaf idaaf idaaf idaaf idah idaaf ifaaf ifaaf ifead ifaaf ifead ihabh igaah igaah\n","idaah idaaf idaaf icaaf icaaf icaaf idah idaaf idaaf idaaf idaad ifaah ifaah idaah\n","iffaj iffaj iffaj iffaj iefaj iefaj iefaj igeaj ifeaj ifeaj igeaj igeaj ifaah ifaah igeah\n","ihfaj ihfaj ihfaj ihfaj ijfaj ijfaj ijfaj iifaj iifaj iifaj ijfaj ijfah ikfaj ikfaj ikfah\n","ifcah ifcah ifcah icaah icaah icaah idcah idcah ifcah ifcah icaah icaah icaah idabh idach\n","======================================== SAMPLE 42 ========================================\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","afaa\n","\n","aaai\n","\n","aiabh\n","\n","ihfaj\n","\n","iifaj\n","\n","iifaj\n","\n","iifaj\n","\n","iifaj\n","\n","iifaj\n","\n","iifaj\n","\n","iifaj\n","\n","iifaj\n","\n","iifaj\n","\n","iifaj\n","\n","ipfaj\n","\n","iqfaj\n","\n","iqfaj\n","\n","iqcaj\n","\n","iqcaj\n","\n","iqcaj\n","\n","iqcaj\n","\n","iqcaj\n","\n","ipfaj\n","\n","iqfaj\n","\n","ipfaj\n","\n","ipfaj\n","\n","iqcaj\n","\n","iqcaj\n","\n","iqfaj\n","\n","iqgaj\n","\n","iqgaj\n","\n","iqgaj\n","\n","isgaj\n","\n","iqgaj\n","\n","iqgaj iqgaj isgaj iqgaj irgaj isgaj iqgaj irgaj isgaj iqgaj irgaj isgaj\n","iheaj\n","iheaj\n","iheaj\n","iheaj\n","iheaj\n","iheaj\n","ihdaj\n","iheaj\n","iheaj\n","iheaj\n","iheaj\n","iheaj\n","iheaj\n","iheaj\n","ijeaj ijeaj ijeaj ikeaj ikeaj ijeaj ijeaj iheaj iheaj ikeaj ikeaj\n","iheaj\n","ihfaj\n","iheaj\n","iheaj\n","iheaj\n","======================================== SAMPLE 43 ========================================\n","afcae afcae afcae ahcae ahcae ahcae ahcae ahcae ahcae ahcae ahcae ahcae ahcae ahcbe iacce iaccf iaccf\n","ahbae ahbae ahbae ahbae ahfae ahfae ahfae ahbae ahbae ahbae ahbae ahbae ahbbe iabce iabce\n","ahbae ahbae ahbae ahbae ahfae ahfae ahfae ahbae ahbae ahbae ahbae ahbae ahbbe iabce iabaf iacaf\n","ahbaj ahbaj ahbaj ahbaj ahbac ahbaj ahbaj ahbaj ahbaj ahbaj ahbah ahbaj ahbaj ahbah iabah\n","ahbai ahbai ahbai ahfai ahfac ahbaj ahbai ahbai ahfai ahfai ahhag ighag ighah ihfac ihfac\n","ahbac ahbac ahbac ahfac ahfac ahfac ahfac ahbaj ahbac ahbac ahfah ahbac ahfbh iffah iffah\n","ihgag ihgag ihgag ifgag ifgag ifgag idgag idgag idgag ihgag ihgag ihgah ihgag ijgag ijgbh ilgah ilgah\n","idgag idgag idgag icgag icgag icgag idgag idgag idgag idgag icgag icgah icgag ijgag ijgbh ikgah ikgah\n","ifgab ifgab ihgab ihgab iggab iggab idgab idgab ijgab ihgab ihgab ijgab iggab iggab iggah iigab iigab\n","ihgab ihgab iggab iggab iigab iigab ihgab ihgab iggab iggab ihgab ijgab iggab iggah ihgac ihgac\n","ijdab ijdbab ijdbab ildab ildab imdab iodab indab indab iodab imdab iodab indab indbh indch irdab irdab\n","ifdab ifdab ildab ikdab ikdab iefab iefab iffab iffab ikfab ikfab ijfab ijdab ijdbb ikdcb ikdcb\n","ifdab ifdab ildab ikdab ikdab iefab iefab iffab iffab ikfab ikfab ijfab ijfbb ijfcb ijfcb ijfcb\n","ifbab ifbab ikbab iibab ikbab iefab iefab iffab iffab ikfab ikbab iibab iibab ijbab iibbh ijbch ijbch\n","ikbab ikbab iibab iibab ijbab ijbab ikbab ikbab iibab iibab ijbab ijbab ihbab ihbbh ijbci ijbci ijbci\n","ifbaj ifbaj iibaj iibaj igbaj igbaj ifbaj ikbaj ikbaj iibaj iibaj ijbaj ihbaj igbaj igbbj ifbca ifbca\n","iibaj iibaj ijbaj ijbaj ijcaj ijcaj iicaj iicaj ikcaj ikcaj ikcaj ijcaj ihcbj ijccj ijbcj ilbcj\n","iibaj ihbaj ijbaj ikbaj iibaj iibaj igbaj ijbaj ijbaj ikbaj ikbaj ijbaj ihbbj ijbca ijbca\n","iibaj ihbaj ikbaj ikfaj iibaj ihbaj igbaj iibaj ikbaj ikbaj ijbaj ikbaj ijbbj ijbca ij\n","======================================== SAMPLE 44 ========================================\n","dafad ijdad ijdad ijdad ikdad ikdad ihdbd ihdbd ihdbd ihdcg ihdcg ihdcg\n","iifad ijfad ijfad ijfad ikfad ikfad ihfbd ihfbd iifag iifah ilfah ilfah imfbd ijfbd ikfbd\n","iifad ihfad ihfad ijfad ikfad ikfad ihfbd ihfbd iifag iffah ilfah ijfah ijbbd ijbcj ijbcj\n","ikfaj ikfaj ikfaj ijfaj ijfaj ijfaj iifaj iifaj ikfaj ikfah ikbaf ijbaf ilbaf ilcbh imcch incch\n","iibaj ihbaj ihbaj ijbaj ijbaj ihcaj ihcaj iibaj ihbaj ihbah iifaf ijfaf ilfaf ilfbf imfaf imfaf\n","ihfaj ihfaj ikfaj ikfaj iifaj ihfaj ihfaj iifaj iffaj iffah iifaf ijfaf ilfaf ilfbf imfaf imfaf\n","ikfaf ikfaf imfaf imfaf ikfaf ikfaf iigaf iigaf ikfaf ikfah ikbaf ijbaf ijbah ijdah ijfah ijfah\n","ilbaf ikbaf iibaf iibaf ikbaf ikfag ikfag imfag imbaf ilbaf ikbaf iibaf iibah imbaf imfag ikbaf\n","iobaj iobaj ipbaj ipbaj iodaj iodaj imdaj ildaj iqdaj iodaj ipdaj ipdah iodaf imdaf imdbf iodcf iqdcf\n","iodaj ipdaj indaj indaj iodaj iodaj ildaj ildaj ipdaj indaj indaj ipdah ipdaf iqfaf iqdaf iqdaf\n","ipdah ipdah iqbah iqbah iodab iodab ildab irdah ipdah ipdah isdah isdah isdah itdah itdbh iudch iudch\n","indah indah inaah inaah imdab imdab ikdah ikfah ipfah ipfah infah inaaf ipaaf ipabh iraah iraah\n","ipaaf ipaaf ioaaf ioaaf ipaaj ipaaj iqaaj ipcaf ipcaf irfaf irfaf ipcaf ipfaf ipabf iqaaf iqaaf\n","ildaf ildaf indaf indaf ileaj ileaj ildaf ildaf imdaf imdaf ildaf ildaf imdaf indaf indbf ipaaf ipaaf\n","imaaf imaaf ioaaf ioaaf inaaj inaaj imaaf ilaaf ilaaf ioaaf ioaaf imaaf imaaf ioabf iqaaf iqaaf\n","ipaae ipaae iraae iraae ipaaj ipaaj iqaac ipaac itaac itaae ipaae ipaae iraae iraba iraca isaae\n","inaae iraae imaae ioaae inaaj inaaj ipeac ipeac iteae iteae ireae ireae iteac itebc iraec iraec\n","ipaaf iraaf imaaf ioaaf inaaj inaaj ipeac ipeac iteae iteae ireae ireac iteae ircbe iraec ircec\n","ipaaf ioaaf imaaf ioaae inaaj inaaj ipeac ipeac iraae iraaf ipabf irabf iraae irace iraace\n","ircaf irfac imfac irfac iqcag iqcag ipcag ircae ipcaf ircaf iscdf iscaf itfae iteae itaae ixaae\n","ipaaj ipaaj iraaj iraaj ipeaj i\n","======================================== SAMPLE 45 ========================================\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","ai\n","\n","ai\n","\n","ai\n","\n","ai\n","\n","ai\n","\n","ai\n","\n","ioc\n","\n","iqc\n","\n","iqc\n","\n","iqc\n","\n","iqc\n","\n","iqc\n","\n","ioa\n","\n","iqa\n","\n","iqa\n","\n","iqa\n","\n","iqa\n","\n","iqa\n","\n","iqa\n","\n","ioa\n","\n","iqa\n","\n","iqa\n","\n","iqa\n","\n","iqaa\n","\n","iqa\n","\n","iqaaa\n","\n","ipaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","ipaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","ipaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","ipaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaaa\n","\n","iqaaa\n","\n","iqaaaa\n","\n","iqaaaa\n","\n","ipaaa\n","\n","iqaaa\n","\n","iqaaa\n","\n","iqaaaa\n","\n","iqaaa\n","\n","iqaaaa\n","\n","iqaaa\n","\n","iqaaaa\n","\n","ipaaa\n","\n","iqaaa\n","\n","iqaaaa\n","\n","iqaaaa\n","\n","iqaaa\n","\n","iqaaaa\n","\n","iqaaa\n","\n","iqaaaa\n","\n","ijaaa\n","\n","iraaa\n","\n","iraaa\n","\n","iraaa\n","\n","iraaa\n","\n","iraaa\n","\n","isaaa\n","\n","itaaa\n","\n","jaaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ilaaa\n","\n","ilaaa\n","\n","ilaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ilaaa\n","\n","ilaaa\n","\n","ilaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ilaaa\n","\n","ilaaa\n","\n","ilaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ilaaa\n","\n","ilaaa\n","\n","ilaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ihaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","ijaaa\n","\n","\n","======================================== SAMPLE 46 ========================================\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","acai\n","\n","aiacg\n","\n","aiagg\n","\n","iagag\n","\n","iagag\n","\n","iigag\n","\n","ihaag\n","\n","ihaag\n","\n","iigag\n","\n","ihaag\n","\n","iigag\n","\n","iigag\n","\n","ihaag\n","\n","imgag\n","\n","iocag\n","\n","ipcag\n","\n","iocag\n","\n","iocag\n","\n","iocag\n","\n","iocag\n","\n","imgag\n","\n","iocag\n","\n","imgag\n","\n","iocag\n","\n","imgag\n","\n","inbaj\n","\n","iobaj\n","\n","iobaj\n","\n","iqbaj\n","\n","iqbaj\n","\n","iqeaj\n","\n","ioeaj\n","\n","ioeaj\n","\n","iqaaj\n","\n","iqaaj\n","\n","ioeaj\n","\n","ioeaj\n","\n","iqeaj\n","\n","iqeaj\n","\n","iqeaj\n","\n","iqeaj\n","\n","iqeaj\n","\n","iqeaj\n","\n","ioeaj\n","\n","ioeaj\n","\n","ioeaj\n","\n","iqeaj\n","\n","iqeaj\n","\n","iqeaj\n","\n","iqeaj\n","\n","iqeaj\n","\n","ilaaj\n","\n","jaaah\n","\n","jaaah\n","\n","jaaah\n","\n","ijaaa ijaaa\n","\n","ijaaa ilaaa\n","\n","ilaaa ilaaa\n","\n","iwaaj iwaaj\n","\n","iuhaj iuhaj\n","\n","iuhaj ixhaj\n","\n","ixhaj ixhaj\n","\n","iuhaj ixhaj\n","\n","iuhaj ixhaj\n","\n","jaaah ikaah\n","\n","jaaah ikaah\n","\n","jaaah imaah\n","\n","imaah imaah\n","\n","ipaah ipaah\n","\n","ipaah ipaah\n","\n","iqaah iqaah\n","\n","iqaah iqaah\n","\n","iqeah iraah\n","\n","iraah iraah\n","\n","ilaah ilaah\n","\n","ilaah ilaah\n","\n","ihaah ihaah\n","\n","iha\n","======================================== SAMPLE 47 ========================================\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","aa\n","\n","ae\n","\n","ai\n","\n","ae\n","\n","ai\n","\n","ai\n","\n","ae\n","\n","iie ihe ihe ime ijead ijeag ijead inead indead indad ioead inbad iobad ipbad\n","iha igaah ihaah ifaah idaah ihdah ihdah ihaah ifaah idaah idaah igaah ikdah iidah ijdbh ijdch ilcch\n","iha igaag ihaag ifaah idaah ihdah ihdah ihaag igaag igaag idaah ifdag iddah iddbh iidch ihdch\n","idca idcai ihcai ifcaa igdaa igdaa ihdai iidca iidca ijdaa ildaa ihdai ikdag ikdag ikgag imgag\n","ildaf ikdaf imdaf ijdaf ildaf ikdaf indaf imdaf ildaf ikdaf imdaf ipdaf ipdaf iqdaf iqdbf irdcf\n","iidaf imdaf ikdaf iqdaf iidaf imdaf indaf ipdaf irdaf ipdaf iqdaf ikdaf imdbf ipdaf indaf\n","imaaf imaaf imaaf imeaf imeaf imeaf ileaf ineaf ineaf imeaf imeaf imaaf iofbf ioaah iqaah\n","ijdaf ijfaf ijfaf iqfaf iidaf ijdaf ikdaf ijfaf ijfaf iqfaf iqfaf irfbf irfcf isfaf isfaf\n","ikfaf ikfaf ikfaf ijfaf iifaf ikfaf ileaf ileaf ikfaf ikfaf ikfaf ijfaf ijfbf ilfaf ilfaf\n","iifaf iifaf ihfaf ijfaf iifag iifag ik\n","======================================== SAMPLE 48 ========================================\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","dafag\n","\n","eafag\n","\n","eafag\n","\n","eafag\n","\n","eafag\n","\n","iabag\n","\n","iabag\n","\n","iabag\n","\n","iabag\n","\n","iabag\n","\n","iabag\n","\n","iabag\n","\n","iabag\n","\n","iabag\n","\n","iabag\n","\n","iabag\n","\n","iodag\n","\n","iodag\n","\n","iodag\n","\n","iodag\n","\n","iodag\n","\n","iodag\n","\n","iodag\n","\n","ipdag\n","\n","ipdag\n","\n","ipdag\n","\n","iogag\n","\n","iogag\n","\n","iogag\n","\n","imgag\n","\n","imgag\n","\n","imgag\n","\n","iqgag\n","\n","iqgag\n","\n","iqgag\n","\n","iqgag\n","\n","iogag\n","\n","iogag\n","\n","iogag\n","\n","imgag\n","\n","imgag\n","\n","imgag\n","\n","iqgag\n","\n","iqgag\n","\n","iqgag\n","\n","iqgag\n","\n","iogag\n","\n","iogag\n","\n","iogag\n","\n","imgag\n","\n","imgag\n","\n","iqgag\n","\n","iqgag\n","\n","iqgag\n","\n","iogag\n","\n","iogag\n","\n","iogag\n","\n","imgag\n","\n","imgag\n","\n","iqgag\n","\n","iqgag\n","\n","iqgag\n","\n","iogag\n","\n","iogag\n","\n","iogag\n","\n","imgag\n","\n","imgag\n","\n","iqgag\n","\n","iqgag\n","\n","iqgag\n","\n","iogag\n","\n","iogag\n","\n","iogag\n","\n","imgag\n","\n","imgag\n","\n","ikgag\n","\n","ikgag\n","\n","ikgag\n","\n","ilgag\n","\n","ilgag\n","\n","ilgag\n","\n","imgag\n","\n","imgag\n","\n","imgag\n","\n","imgag\n","\n","imgag\n","\n","imdag\n","\n","imdag\n","\n","ilgag\n","\n","ilgag\n","\n","ilgag\n","\n","imgag\n","\n","imgag\n","\n","imgag\n","======================================== SAMPLE 49 ========================================\n","adfai adfai adfai afci iadai iadai iadai ildai ildai iqdai iqdai iqdai iqdai iqdai iqdbi isdci isdci\n","ildai ildai ildai ikdai ikdai ildai ikeai ijdai ijdai ijdai ikdai ikdai ikdbi ilgci ilgci\n","iqdai qdai qdai irdai irdai qdai ipdai ipdai iqdai qdai qdai iqdai qdbi isgci isgci\n","imgag imgaf imgaf iogaj imgaj ipgaj isgaj irgaj itgaj irgah itgah ivgah ivgah ixgbi ixgai izaag izaag\n","ivgag ivgaf ivgaf iugaj iugaj iueaj ixeaj ixeaf iveaf iveaf iweaj ixeaf ixeaf izfbi izfai isfai\n","itdaj itdaj isdaj isdaj itdaj iteaj iveaj iveaj iteaj iteah iteah iveaj iveah ixabi ivdai ixdai\n","irfai irfai irfai ircaj ircaj ircaj iqcaj iqfaj irfaj irfaj ircaj ircah ircbi ircai iufai iufai\n","ipaaf ipaaf ipaaf iraaj iraaj iraaj ivaaj ipaaj ipaaj ipaah irdaj irdaj irdah itdah itdbi itdai ivaag iwag\n","irfai irfai irfai ircaj ircaj ircaj ivaaj ipaaj ipaaj irfaj irfah irfah isbag itfah itfai itfai\n","ipfai ipfai ipfai irfaj irfaj irfaj irvaj ipfaj ipfaj ipfah ipfah ipbag irbag irfaa irfaa\n","irfaj irfaj irfaj ircaj ircaj ircaj ivaaj ipfaj ipfaj irfaj irfah irfah isbag isfaa isfaa\n","infaj infaj infaj iofaj iofaj iofaj iocaj ineaj imeaj imeaj iqeaj iqeah ireah ireab iraab iraab\n","ipaac ipaac ipaac indaj ipaaj ipaaj iodaj ineaj imeaj imeaj ioeaj ipeah ipebh ipfah iqfah iqfah\n","ildac ildac ildac ikdaj ikdaj ikdaj ildaj imeaj ileaj ileah imeac imeah iqfac iqdac iqdac\n","ipaaf ipaaf ipaaf ipeaj ipeaj ipeaj ipeaj ioeaj ioeaf ipaaf ipaaf ipeah ipeac isfac isfac\n","ineaf imeaf imeaf imeaj ioeaj ioeaj imeaj ileaf imebf ilebf inace imeaf imeaf imfah iofah\n","irfai irfai irfai ircai ircai ircii ircii itdai itdai itdai irfai irfah isdai isfah\n","ipaaj ipaaj ipaaj ipeaj ipeaj ipecj ipecj iseaj iseaj ireaj imeaj ipaag ipaaf itaaf itaaf\n","iteaj iteaj iteaj ireaj ireaj iseaj iseaj iteaj iteaj iteag iraag irabg iteaj iveaj iweaj\n","irfae irfae irfae irfae iteae iteae iteae ircae ipcae ipcae ircae irfag irfaf itfaf itfaf\n","ipaae ipaae ipaae iraae iraae ipaae ipaae isaae itaae iraae iraag ipaaf itcaf itfaf isfaf\n","iteaf iteaf iteaf iteaf ive\n","======================================== SAMPLE 50 ========================================\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","a\n","\n","aa\n","\n","aa\n","\n","ae\n","\n","ai\n","\n","ae\n","\n","ai\n","\n","ai\n","\n","ae\n","\n","ai\n","\n","ae\n","\n","ai\n","\n","ae\n","\n","ije\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","ihd\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","ihc\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","ijc\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","ijc\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","ipd\n","\n","iha\n","\n","ihf\n","\n","ihf\n","\n","ihf\n","\n","ihf\n","\n","ihf\n","\n","ihf\n","\n","ihf\n","\n","ihf\n","\n","ihf\n","\n","ijf\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","iha\n","\n","ijf\n","\n","iha\n","\n","iha\n","\n","ilf\n","\n","ilf\n","\n","ilf\n","\n","ilf\n","\n","ilf\n","\n","ilf\n","\n","ijf\n","\n","ijf\n","\n","ijf\n","\n","ijf\n","\n","ijf\n","\n","jaa\n","\n","jaa\n","\n","jaa\n","\n","jaa\n","\n","jaa\n","\n","jaa\n","\n","jaa\n","\n","jfaj\n","\n","jfaj\n","\n","jfaj\n","\n","jfaj\n","\n","jaba\n","\n","jaaa\n","\n","jaaa\n","\n","jaaa\n","\n","jaaa\n","\n","jfaj\n","\n","jfaj\n","\n","kbaj\n","\n","kbaj\n","\n","lbaj\n","\n","lbaj\n","\n","lbaj\n","\n","lbaj\n","\n","lbaj\n","\n","lbaj\n","\n","lbaj\n","\n","lbaj\n","\n","mlaj\n","\n","mlaj\n","\n","mlaj\n","\n","nbaj\n","\n","nbaj\n","\n","nbaj\n","\n","nbaj\n","\n","obaj\n","\n","obaa imdaa imdaa ipdaj ipdaj irfaa irfaa irfaa irfaa irfaa irfaa\n","ihea\n","\n","ihea\n","\n","ihea\n","\n","ihea\n","\n","ihea\n","\n","ihea\n","\n","ihea\n","\n","ihea\n","\n","ihea\n","\n","ihea\n","\n","ihea\n","\n","imgaa imfaa imfaa imgaj imgaj imeaa imeaa imeaa imeaa imeaa\n","\n","ihaa\n","\n","ihaa\n","\n","ihaa\n","\n","ihaa\n","\n","ihaTraceback (most recent call last):\n","  File \"src/generate_unconditional_samples.py\", line 77, in <module>\n","    fire.Fire(sample_model)\n","  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n","    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n","  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n","    target=component.__name__)\n","  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n","    component = fn(*varargs, **kwargs)\n","  File \"src/generate_unconditional_samples.py\", line 69, in sample_model\n","    out = sess.run(output)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","KeyboardInterrupt\n","^C\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VM1Hag-JL3Bt","colab_type":"text"},"source":["To check flag descriptions, use:"]},{"cell_type":"code","metadata":{"id":"Sdxfye-SL66I","colab_type":"code","outputId":"052b1161-a19c-4709-d35f-e86390b26301","executionInfo":{"status":"ok","timestamp":1582795539247,"user_tz":300,"elapsed":5506,"user":{"displayName":"Empty Vessels","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCu0WTunLhjQvKFO7ZWnAc7OCxkL1Km5IWiiPPv=s64","userId":"13779790377842426643"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["!python3 src/generate_unconditional_samples.py -- --help"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","\u001b[1mNAME\u001b[0m\n","    generate_unconditional_samples.py - Run the sample_model :model_name=117M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=0 : Number of samples to return, if 0, continues to generate samples indefinately. :batch_size=1 : Number of batches (only affects speed/memory). :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling, overriding top_k if set to a value > 0. A good setting is 0.9.\n","\n","\u001b[1mSYNOPSIS\u001b[0m\n","    generate_unconditional_samples.py <flags>\n","\n","\u001b[1mDESCRIPTION\u001b[0m\n","    Run the sample_model :model_name=117M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=0 : Number of samples to return, if 0, continues to generate samples indefinately. :batch_size=1 : Number of batches (only affects speed/memory). :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :top_p=0.0 : Float value controlling diversity. Implements nucleus sampling, overriding top_k if set to a value > 0. A good setting is 0.9.\n","\n","\u001b[1mFLAGS\u001b[0m\n","    --model_name=\u001b[4mMODEL_NAME\u001b[0m\n","    --seed=\u001b[4mSEED\u001b[0m\n","    --nsamples=\u001b[4mNSAMPLES\u001b[0m\n","    --batch_size=\u001b[4mBATCH_SIZE\u001b[0m\n","    --length=\u001b[4mLENGTH\u001b[0m\n","    --temperature=\u001b[4mTEMPERATURE\u001b[0m\n","    --top_k=\u001b[4mTOP_K\u001b[0m\n","    --top_p=\u001b[4mTOP_P\u001b[0m\n"],"name":"stdout"}]}]}